<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-27BZJEV10H"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-27BZJEV10H');
  </script>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-NXPKZCWC');</script>
    <!-- End Google Tag Manager -->

  <!-- =======================  META  ======================= -->
  <meta charset="utf-8" />
  <title>SSA — Parallel Reasoning Sample Set Aggregator</title>
  <meta name="description" content="SSA: a compact LLM that learns to aggregate across parallel samples set reasoningand close the oracle-gap of test-time scaling." />
  <meta name="keywords" content="large language models, reasoning, reinforcement learning, test-time scaling" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXPKZCWC"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav> -->

  <!-- ========================================================= -->
  <!--  ░█▀█░█▄█░█▀█░█░█░█░█░█▀▀░█░█  HERO BANNER                -->
  <!-- ========================================================= -->
  <section class="hero is-fullheight-with-navbar">
    <div class="hero-body is-justify-content-center is-align-items-center">
      <div class="container has-text-centered">
        <h1 class="title is-1">SSA: Sample Set Aggregator</h1>
        <h2 class="subtitle is-4">Learning to Reason Across <em>Parallel&nbsp;Samples</em> for LLM Reasoning</h2>

        <!-- AUTHORS INLINE -->
        <p class="is-size-6 mb-1">
          <a href="https://user074.github.io/" target="_blank">Jianing&nbsp;Qi</a><sup>1</sup> ·
          <a href="https://xiye17.github.io/" target="_blank">Xi&nbsp;Ye</a><sup>2</sup> ·
          <a href="https://www.bmcc.cuny.edu/faculty/hao-tang/" target="_blank">Hao&nbsp;Tang</a><sup>3</sup> ·
          <a href="https://ccvcl.org/professor-zhigang-zhu/" target="_blank">Zhigang&nbsp;Zhu</a><sup>4</sup> ·
          <a href="https://eunsol.github.io/" target="_blank">Eunsol&nbsp;Choi</a><sup>5</sup>
        </p>
        <p class="is-size-7 mb-4">
          <sup>1</sup>CUNY&nbsp;Graduate&nbsp;Center&nbsp;&nbsp;
          <sup>2</sup>Princeton&nbsp;University&nbsp;&nbsp;
          <sup>3</sup>BMCC,&nbsp;CUNY&nbsp;&nbsp;
          <sup>4</sup>CCNY,&nbsp;CUNY&nbsp;&nbsp;
          <sup>5</sup>New&nbsp;York&nbsp;University
        </p>

        <p class="is-size-6 mb-5">A compact <strong>0.5 – 3 B</strong> add-on that reaches <strong>94 % of Pass@5</strong> (only 6 % relative gap) — all without any base-model fine-tuning.</p>

        <div class="buttons is-centered">
          <a class="button is-dark is-rounded" href="https://arxiv.org/abs/2506.09014v1" target="_blank"><i class="ai ai-arxiv mr-1"></i>Paper</a>
          <a class="button is-dark is-rounded" href="https://github.com/user074/ssa" target="_blank"><i class="fab fa-github mr-1"></i>Code</a>
          <a class="button is-dark is-rounded" href="https://huggingface.co/spaces/your‑org/SSA-demo" target="_blank"><i class="fas fa-rocket mr-1"></i>Model</a>
        </div>
        
        <figure class="mt-6">
          <img src="./static/images/SSA_arch.png" alt="Architecture diagram comparing SSA to parallel and sequential test‑time scaling" loading="lazy" style="width: 80%;" />
        </figure>


      </div>
    </div>
  </section>


  <!-- ========================================================= -->
  <!--  ABSTRACT                                                -->
  <!-- ========================================================= -->
  <section class="section has-background-light">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Abstract</h2>
      <p>Scaling test‑time compute by <em>sampling</em> multiple reasoning paths yields large gains but leaves an oracle gap. We introduce <strong>SSA</strong>, a tiny LLM fine‑tuned with Group‑Relative PPO to read <code>k</code> candidate solutions and emit one final answer. On GSM8K, MATH, AIME‑24, AMC‑23 and OlympiadBench, SSA reaches <strong>56.1&nbsp;%</strong> accuracy—just <strong>3.6&nbsp;pp</strong> shy of the Pass@5 oracle—and beats 7 B process‑reward models while training on &lt;5 % of their data. The model generalises across base‑family (Qwen → Llama‑3), base‑size (7 → 32 B) and <code>k</code> without re‑tuning.</p>
    </div>
  </section>

  <!-- ========================================================= -->
  <!--  ARCHITECTURE                                            -->
  <!-- ========================================================= -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Method at a Glance</h2>
      <!--  Animated teaser  -->
      <figure class="mt-6">
        <img class="teaser" src="./static/images/SSA.gif" alt="Animated overview of the SSA pipeline" width="640" loading="eager" />
        <figcaption class="is-size-7 has-text-grey">Parallel candidates → small RL‑tuned <strong>SSA</strong> → final answer</figcaption>
      </figure>

      <ul class="content">
        <li><strong>Step 1:</strong> Freeze a base LLM; sample <code>k</code> solutions.</li>
        <li><strong>Step 2:</strong> Concatenate solutions + prompt → SSA (0.5–3 B).</li>
        <li><strong>Training:</strong> GRPO with a sparse, verifiable reward (correct / format).</li>
      </ul>
    </div>
  </section>

  <!-- ========================================================= -->
  <!--  RESULTS –                                                -->
  <!-- ========================================================= -->
  <section class="section" id="results">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>
      <div class="content">
        <p><strong>SSA‑3B</strong> surpasses a 7 B process‑reward verifier. The same checkpoint can be plugged into frozen base models up to 32 B with no re‑tuning.</p>
        <p>The charts below show the average of GSM8K, MATH, AIME‑24, AMC‑23 and OlympiadBench.</p>

      </div>

      <!-- overall bar / line chart -->
      <figure class="mb-5"><img src="./static/images/all_model_comparison.png" alt="Bar chart comparing SSA to parallel‑scaling baselines" loading="lazy" /></figure>

      <!-- miniature sortable leaderboard -->
      <table class="table is-striped is-hoverable is-fullwidth" id="leaderboard">
        <thead><tr><th>Method</th><th>Params</th><th>k</th><th>Avg&nbsp;Acc ↑</th></tr></thead>
        <tbody>
          <tr><td class="has-text-grey">Pass@1 (base)</td><td>7 B</td><td>1</td><td>45.5</td></tr>
          <tr><td class="has-text-grey">Pass@5 (oracle)</td><td>—</td><td>5</td><td>59.7</td></tr>
          <tr><td>Majority vote</td><td>—</td><td>5</td><td>49.7</td></tr>
          <tr><td>Qwen‑PRM</td><td>7 B</td><td>5</td><td>53.0</td></tr>
          <tr class="has-background-primary-light"><td><strong>SSA (ours)</strong></td><td>3 B</td><td>5</td><td><strong>56.1</strong></td></tr>
        </tbody>
      </table>

      <div class="content">
        <p>Below we also juxtapose SSA‑3B with <em>sequential</em> RL models that fine‑tune the <u>entire</u> 7 B / 14 B / 32 B backbone. Despite its 10× smaller footprint, SSA stays within 2–3 pp accuracy with similar tokens during test time.</p>
      </div>
      <!-- sequential RL vs SSA comparison figure -->
      <figure class="mt-5"><img src="./static/images/inference_size_comparison.png" alt="Inference‑time compute vs. accuracy: SSA‑3B vs sequential‑RL (7/14/32 B)" loading="lazy" /></figure>
    </div>
  </section>

  <!-- ========================================================= -->
  <!--  Discussion                                                -->
  <!-- ========================================================= -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Discussion</h2>
      <div class="content">
        <p>Key Questions:</p>
        <ul>
          <li><strong>Does RL optimize the output distribution?</strong> We find that we can separate the reasoning abilities out from the model weights. By plug a small SSA on top of the base model outputs, we can signficantly increase the performance just like full RL training. It is possible to view SSA as shaping the output distribution of the base model not through weights but through sampled outputs.</li>
          <li><strong>How helpful is the thinking process?</strong> Similar to the previous works, we find that thinking process might not be helpful for the final answer in terms of benchmark performance. Is thinking necessary for the model? Probably not. But it does seem that thinking process is a bit more robust to our of domain generalization when we test it on the other tasks such as MMLU-PRO and ARC-C.</li>
          <li><strong>Can RL learn new reasoning abilities?</strong> The more interesting part is to use the SSA on top of the truncated reasoning outputs. We find that even a small SSA can recover most of the answer even when last 10% of the reasoning process and answers are truncated. However, pure RL version is much worse than the RL+SFT version. We believe it is an interesting direction to explore stitching the reasoning processes to arrive at the final answer.</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- BIBTEX ---------------------------------------------- -->
  <section class="section" id="bibtex">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">BibTeX</h2>
      <pre><code>@inproceedings{xxxxx,
  title     = {Learning to Reason Across Parallel Samples for LLM Reasoning},
  author    = {Qi, Jianing and Ye, Xi and Tang, Hao and Zhu, Zhigang and Choi, Eunsol},
  booktitle = {xxxxx},
  year      = {2025}
}</code></pre>
    </div>
  </section>

  <!-- FOOTER ---------------------------------------------- -->
  <footer class="footer">
    <div class="content has-text-centered is-size-7">
      <p>© 2025 Qi et al. · Site adapted from the <a href="https://nerfies.github.io/">Nerfies</a> template (CC BY‑SA 4.0).</p>
    </div>
  </footer>

  <!-- Inline script to make leaderboard sortable (optional) -->
  <script>
    // Tiny sort helper — no library required
    document.querySelectorAll('#leaderboard th').forEach(th => th.addEventListener('click', () => {
      const tbody = th.closest('table').querySelector('tbody');
      [...tbody.querySelectorAll('tr')]
        .sort((a,b)=>parseFloat(b.children[3].textContent)-parseFloat(a.children[3].textContent))
        .forEach(tr=>tbody.appendChild(tr));
    }));
  </script>

</body>
</html>
